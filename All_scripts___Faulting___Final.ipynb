{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO43ESjkH30pLMv+dZlIjiN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sam916060/PhD_Thesis/blob/main/All_scripts___Faulting___Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFR + Default"
      ],
      "metadata": {
        "id": "prpOFaufZaKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "# Feature Scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Create the Random Forest Regression model\n",
        "regressor = RandomForestRegressor(n_estimators=100, random_state=13)\n",
        "\n",
        "# Train the Random Forest Regression model using the training data\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the Test set results\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Print predicted and actual values\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "# Evaluate the Model Performance\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R^2 Score:\", r2)\n"
      ],
      "metadata": {
        "id": "ke4_zhGFZZVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB + Default"
      ],
      "metadata": {
        "id": "U5BuonkoZdh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "# Feature Scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Create the XGBoost Regression model\n",
        "regressor = XGBRegressor(objective ='reg:squarederror', random_state=13)\n",
        "\n",
        "# Train the XGBoost Regression model using the training data\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the Test set results\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Print predicted and actual values\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "# Evaluate the Model Performance\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R^2 Score:\", r2)\n"
      ],
      "metadata": {
        "id": "SdT5X2AJZgEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFR + RGS"
      ],
      "metadata": {
        "id": "NM5x9F7HPaS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJi_rXC3PQIb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "dataset\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 13)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from pprint import pprint\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
        "n_estimators.append(100)\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_features.append(None)\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_split.append(None)\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "min_samples_leaf.append(None)\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "bootstrap.append(None)\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "pprint(random_grid)\n",
        "\n",
        "regressor = RandomForestRegressor()\n",
        "rf_random = RandomizedSearchCV(estimator = regressor, param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=0, n_jobs = -1)\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "# After running rf_random.fit(X_train, y_train):\n",
        "best_params = rf_random.best_params_\n",
        "print(best_params)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Get the best model\n",
        "best_model = rf_random.best_estimator_\n",
        "\n",
        "# Make predictions on training and test sets\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on training set\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Training set performance:\")\n",
        "print(\"MAE: {:.3f}\".format(mae_train))\n",
        "print(\"MSE: {:.3f}\".format(mse_train))\n",
        "print(\"RMSE: {:.3f}\".format(rmse_train))\n",
        "print(\"R2: {:.3f}\".format(r2_train))\n",
        "\n",
        "# Evaluate the model on test set\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nTest set performance:\")\n",
        "print(\"MAE: {:.3f}\".format(mae_test))\n",
        "print(\"MSE: {:.3f}\".format(mse_test))\n",
        "print(\"RMSE: {:.3f}\".format(rmse_test))\n",
        "print(\"R2: {:.3f}\".format(r2_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM + Default"
      ],
      "metadata": {
        "id": "vFcMnMoqSJI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Create the SVR model\n",
        "regressor = SVR(kernel='rbf', C=10, epsilon=0.1)\n",
        "\n",
        "# Train the SVM Regression model using the training data\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the Test set results\n",
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "# Evaluate the Model Performance\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "vrthCzAgSIKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFR + BOT"
      ],
      "metadata": {
        "id": "G7Ml0hRrUTYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "dataset\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "## Splitting the dataset into the Training set and Test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 13)\n",
        "\n",
        "def random_forest_r2_score(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features):\n",
        "    regressor = RandomForestRegressor(n_estimators=int(n_estimators),\n",
        "                                      max_depth=int(max_depth),\n",
        "                                      min_samples_split=int(min_samples_split),\n",
        "                                      min_samples_leaf=int(min_samples_leaf),\n",
        "                                      max_features=int(max_features),\n",
        "                                      random_state=6)\n",
        "    regressor.fit(X_train, y_train)\n",
        "    y_pred = regressor.predict(X_test)\n",
        "    return r2_score(y_test, y_pred)\n",
        "\n",
        "BO = BayesianOptimization(random_forest_r2_score,\n",
        "                         {'n_estimators': (100, 1000),\n",
        "                          'max_depth': (5, 20),\n",
        "                          'min_samples_split': (2, 10),\n",
        "                          'min_samples_leaf': (1, 5),\n",
        "                          'max_features': (1, X.shape[1])})\n",
        "\n",
        "BO.maximize(init_points=5, n_iter=20)\n",
        "\n",
        "print(BO.max)\n",
        "\n",
        "best_params = BO.max['params']\n",
        "n_estimators = int(best_params['n_estimators'])\n",
        "max_depth = int(best_params['max_depth'])\n",
        "min_samples_split = int(best_params['min_samples_split'])\n",
        "min_samples_leaf = int(best_params['min_samples_leaf'])\n",
        "max_features = int(best_params['max_features'])\n",
        "\n",
        "regressor = RandomForestRegressor(n_estimators=n_estimators,\n",
        "                                  max_depth=max_depth,\n",
        "                                  min_samples_split=min_samples_split,\n",
        "                                  min_samples_leaf=min_samples_leaf,\n",
        "                                  max_features=max_features,\n",
        "                                  random_state=6)\n",
        "\n",
        "# Fit the model using the best parameters\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the training and testing sets\n",
        "y_train_pred = regressor.predict(X_train)\n",
        "y_test_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate the R2 score for the training and testing sets\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"R2 score for training set: {:.3f}\".format(train_r2))\n",
        "print(\"R2 score for testing set: {:.3f}\".format(test_r2))\n",
        "\n",
        "# Calculate the MAE, MSE, and RMSE for the training and testing sets\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "print(\"MAE for training set: {:.3f}\".format(train_mae))\n",
        "print(\"MSE for training set: {:.3f}\".format(train_mse))\n",
        "print(\"RMSE for training set: {:.3f}\".format(train_rmse))\n",
        "\n",
        "print(\"MAE for testing set: {:.3f}\".format(test_mae))\n",
        "print(\"MSE for testing set: {:.3f}\".format(test_mse))\n",
        "print(\"RMSE for testing set: {:.3f}\".format(test_rmse))\n"
      ],
      "metadata": {
        "id": "PMK8LN21UU3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB + BOT"
      ],
      "metadata": {
        "id": "lU8vVtkLWQ0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "## Importing the dataset\n",
        "\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "## Splitting the dataset into the Training set and Test set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def xgboost_regressor(max_depth, learning_rate, n_estimators, gamma, min_child_weight, subsample, colsample_bytree, reg_alpha):\n",
        "    regressor = XGBRegressor(max_depth=int(max_depth), learning_rate=learning_rate, n_estimators=int(n_estimators), gamma=gamma, min_child_weight=int(min_child_weight), subsample=subsample, colsample_bytree=colsample_bytree, reg_alpha=reg_alpha, random_state=0)\n",
        "    regressor.fit(X_train, y_train)\n",
        "    y_pred = regressor.predict(X_test)\n",
        "    return r2_score(y_test, y_pred)\n",
        "\n",
        "bounds = {\n",
        "    'max_depth': (2, 10),\n",
        "    'learning_rate': (0.01, 0.3),\n",
        "    'n_estimators': (100, 1000),\n",
        "    'gamma': (0, 0.5),\n",
        "    'min_child_weight': (1, 20),\n",
        "    'subsample': (0.1, 1),\n",
        "    'colsample_bytree': (0.1, 1),\n",
        "    'reg_alpha': (0, 1)\n",
        "}\n",
        "\n",
        "optimizer = BayesianOptimization(xgboost_regressor, bounds)\n",
        "optimizer.maximize(init_points=5, n_iter=20)\n",
        "\n",
        "print(\"Final result:\", optimizer.max)\n",
        "\n",
        "best_params = optimizer.max['params']\n",
        "max_depth = int(best_params['max_depth'])\n",
        "learning_rate = best_params['learning_rate']\n",
        "n_estimators = int(best_params['n_estimators'])\n",
        "gamma = best_params['gamma']\n",
        "min_child_weight = int(best_params['min_child_weight'])\n",
        "subsample = best_params['subsample']\n",
        "colsample_bytree = best_params['colsample_bytree']\n",
        "reg_alpha = best_params['reg_alpha']\n",
        "\n",
        "# Fitting the XGBoost Regressor with the best parameters\n",
        "regressor = XGBRegressor(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators,\n",
        "                        gamma=gamma, min_child_weight=min_child_weight, subsample=subsample,\n",
        "                        colsample_bytree=colsample_bytree, reg_alpha=reg_alpha, random_state=0)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Fit the model using the best parameters\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the training and testing sets\n",
        "y_train_pred = regressor.predict(X_train)\n",
        "y_test_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate the R2 score for the training and testing sets\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"R2 score for training set: {:.3f}\".format(train_r2))\n",
        "print(\"R2 score for testing set: {:.3f}\".format(test_r2))\n",
        "\n",
        "# Calculate the MAE, MSE, and RMSE for the training and testing sets\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "print(\"MAE for training set: {:.3f}\".format(train_mae))\n",
        "print(\"MSE for training set: {:.3f}\".format(train_mse))\n",
        "print(\"RMSE for training set: {:.3f}\".format(train_rmse))\n",
        "\n",
        "print(\"MAE for testing set: {:.3f}\".format(test_mae))\n",
        "print(\"MSE for testing set: {:.3f}\".format(test_mse))\n",
        "print(\"RMSE for testing set: {:.3f}\".format(test_rmse))\n",
        "\n"
      ],
      "metadata": {
        "id": "ZdOV79gfWP2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM + BOT"
      ],
      "metadata": {
        "id": "vsvDbXL9W-5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "## Importing the dataset\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "## Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "## Feature Scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "## Define the parameter search space for SVR model\n",
        "param_space = {\n",
        "    'C': Real(0.1, 100.0, 'log-uniform'),\n",
        "    'epsilon': Real(0.01, 1.0, 'log-uniform'),\n",
        "    'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "}\n",
        "\n",
        "## Create the SVR model\n",
        "regressor = SVR()\n",
        "\n",
        "## Create the BayesSearchCV object\n",
        "bot = BayesSearchCV(\n",
        "    estimator=regressor,\n",
        "    search_spaces=param_space,\n",
        "    scoring='r2',\n",
        "    cv=5,\n",
        "    n_iter=100,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=2\n",
        ")\n",
        "\n",
        "## Fit the BayesSearchCV object to the training data\n",
        "bot.fit(X_train, y_train)\n",
        "\n",
        "## Get the best hyperparameters\n",
        "best_params = bot.best_params_\n",
        "\n",
        "## Train the SVM Regression model using the best hyperparameters\n",
        "regressor = SVR(kernel=best_params['kernel'], C=best_params['C'], epsilon=best_params['epsilon'])\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "## Predict the Test set results\n",
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "## Evaluate the Model Performance\n",
        "r2_score(y_test, y_pred)\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, median_absolute_error, explained_variance_score\n",
        "import numpy as np\n",
        "\n",
        "## Predict the Train set results\n",
        "y_train_pred = regressor.predict(X_train)\n",
        "\n",
        "## Predict the Test set results\n",
        "y_test_pred = regressor.predict(X_test)\n",
        "\n",
        "## Print the R2, MAE, MSE, and RMSE for Train and Test data\n",
        "print('Train set')\n",
        "print('R2 score:', r2_score(y_train, y_train_pred))\n",
        "print('MAE:', mean_absolute_error(y_train, y_train_pred))\n",
        "print('MSE:', mean_squared_error(y_train, y_train_pred))\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
        "print('MAPE:', mean_absolute_percentage_error(y_train, y_train_pred))\n",
        "print('MBE:', np.mean(y_train_pred - y_train))\n",
        "print('EVS:', explained_variance_score(y_train, y_train_pred))\n",
        "print('MedAE:', median_absolute_error(y_train, y_train_pred))\n",
        "print('CV:', np.sqrt(mean_squared_error(y_train, y_train_pred)) / np.mean(y_train))\n",
        "\n",
        "print('\\nTest set')\n",
        "print('R2 score:', r2_score(y_test, y_test_pred))\n",
        "print('MAE:', mean_absolute_error(y_test, y_test_pred))\n",
        "print('MSE:', mean_squared_error(y_test, y_test_pred))\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
        "print('MAPE:', mean_absolute_percentage_error(y_test, y_test_pred))\n",
        "print('MBE:', np.mean(y_test_pred - y_test))\n",
        "print('EVS:', explained_variance_score(y_test, y_test_pred))\n",
        "print('MedAE:', median_absolute_error(y_test, y_test_pred))\n",
        "print('CV:', np.sqrt(mean_squared_error(y_test, y_test_pred)) / np.mean(y_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "HCqYg0K1W9tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB + RGS"
      ],
      "metadata": {
        "id": "Y2O_UXk0V4lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "## Importing the dataset\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "## Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "## Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500, 1000, 2000],\n",
        "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
        "    'min_child_weight': [1, 2, 3, 4, 5],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
        "    'reg_lambda': [0.5, 1.0, 1.5, 2.0, 2.5]\n",
        "}\n",
        "\n",
        "## Create an instance of XGBRegressor\n",
        "regressor = XGBRegressor(random_state=0)\n",
        "\n",
        "## Create an instance of RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(regressor, param_grid, cv=5, n_iter=50, scoring='r2', n_jobs=-1, verbose=2, random_state=0)\n",
        "\n",
        "## Fit the RandomizedSearchCV to the Training set\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "## Print the best parameters and the best score\n",
        "print(\"Best parameters: \", random_search.best_params_)\n",
        "print(\"Best score: \", random_search.best_score_)\n",
        "\n",
        "## Use the best parameters to train the XGBRegressor model\n",
        "best_regressor = random_search.best_estimator_\n",
        "best_regressor.fit(X_train, y_train)\n",
        "\n",
        "## Predict the Test set results using the best model\n",
        "y_pred = best_regressor.predict(X_test)\n",
        "\n",
        "## Evaluate the Model Performance\n",
        "print(\"R2 score: \", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "yux9fvzHV3ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN + Basic"
      ],
      "metadata": {
        "id": "kzw1DHErX__1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load necessary libraries and check TensorFlow version\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"Fault_14.02.23.csv\")\n",
        "\n",
        "# Split features and target variable\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "# Feature scaling using MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Build the ANN model\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# Define the model architecture\n",
        "LC_model_5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "LC_model_5.compile(loss='huber', optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False), metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = LC_model_5.fit(X_train, y_train, epochs=500, verbose=1)\n",
        "\n",
        "# Plot training loss and MAE\n",
        "plt.plot(history.history['loss'], 'g', label='Training loss')\n",
        "plt.plot(history.history['mae'], 'm', label='Training MAE')\n",
        "plt.xlabel('Epochs', size='20')\n",
        "plt.ylabel('Loss', size='20')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_loss, test_mae = LC_model_5.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test MAE:\", test_mae)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = LC_model_5.predict(X_test)\n",
        "\n",
        "# Calculate various metrics\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"R^2 Score:\", r2)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Plot predictions against actual values\n",
        "plt.scatter(y_pred, y_test, color='b', edgecolors='c', marker='D')\n",
        "plt.plot([0, 12], [0, 12], color='r', ls='--')\n",
        "plt.text(0.2, 10, 'R2 - {:.2f}'.format(r2), size=10, bbox={'facecolor': 'b', 'alpha': 0.5, 'pad': 10})\n",
        "plt.ylabel('Predicted value', size='14')\n",
        "plt.xlabel('True value', size='14')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate performance on training set\n",
        "y_train_pred = LC_model_5.predict(X_train)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Training set performance:\")\n",
        "print(\"MAE: {:.3f}\".format(mae_train))\n",
        "print(\"MSE: {:.3f}\".format(mse_train))\n",
        "print(\"RMSE: {:.3f}\".format(rmse_train))\n",
        "print(\"R2: {:.3f}\".format(r2_train))\n",
        "\n",
        "# Evaluate performance on test set\n",
        "print(\"\\nTest set performance:\")\n",
        "print(\"MAE: {:.3f}\".format(mae_test))\n",
        "print(\"MSE: {:.3f}\".format(mse_test))\n",
        "print(\"RMSE: {:.3f}\".format(rmse_test))\n",
        "print(\"R2: {:.3f}\".format(r2_test))\n"
      ],
      "metadata": {
        "id": "bG8j3xp4V7Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN"
      ],
      "metadata": {
        "id": "Mw6V1Jf4YaQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score, median_absolute_error, mean_absolute_percentage_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"Fault_14.02.23.csv\")\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Scale the data\n",
        "sc = MinMaxScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# Create the RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(100, input_shape=(X_train.shape[1], 1), return_sequences=True),\n",
        "    tf.keras.layers.LSTM(100, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(100, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(100),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='huber', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=32, verbose=1)\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Metrics calculation\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "mse_test = mean_squared_error(y_test, y_pred)\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Test set performance:\")\n",
        "print(\"R2 score:\", r2_test)\n",
        "print(\"Mean Squared Error:\", mse_test)\n",
        "print(\"Mean Absolute Error:\", mae_test)\n",
        "\n",
        "# Plot predictions against actual values\n",
        "plt.scatter(y_pred, y_test, color='b', edgecolors='c', marker='D')\n",
        "plt.plot([0, 12], [0, 12], color='r', ls='--')\n",
        "plt.text(0.2, 10, 'R2 - {:.2f}'.format(r2_test), size=10, bbox={'facecolor': 'b', 'alpha': 0.5, 'pad': 10})\n",
        "plt.ylabel('Predicted value', size='14')\n",
        "plt.xlabel('True value', size='14')\n",
        "plt.show()\n",
        "\n",
        "# Predictions on training set\n",
        "y_pred_train = model.predict(X_train)\n",
        "\n",
        "# Metrics calculation on training set\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "# Print metrics for training set\n",
        "print(\"\\nTraining set performance:\")\n",
        "print(\"R2 score:\", r2_train)\n",
        "print(\"Mean Squared Error:\", mse_train)\n",
        "print(\"Mean Absolute Error:\", mae_train)\n"
      ],
      "metadata": {
        "id": "8wmDgH_dYbVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM + RGS"
      ],
      "metadata": {
        "id": "g6WL9FdJYcWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, median_absolute_error, explained_variance_score\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('Fault_14.02.23.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Split the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "# Feature Scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Define the parameter grid for SVR model\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'epsilon': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Create the SVR model\n",
        "regressor = SVR()\n",
        "\n",
        "# Create the RandomizedGridSearchCV object\n",
        "random_grid_search = RandomizedSearchCV(estimator=regressor, param_distributions=param_grid, n_iter=100, cv=5, verbose=2, random_state=2, n_jobs=-1)\n",
        "\n",
        "# Fit the RandomizedGridSearchCV object to the training data\n",
        "random_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_grid_search.best_params_\n",
        "\n",
        "# Train the SVM Regression model using the best hyperparameters\n",
        "regressor = SVR(kernel=best_params['kernel'], C=best_params['C'], epsilon=best_params['epsilon'])\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the Test set results\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the Model Performance\n",
        "print(\"Test set performance:\")\n",
        "print('R2 score:', r2_score(y_test, y_pred))\n",
        "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
        "print('MSE:', mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "# Predict the Train set results\n",
        "y_train_pred = regressor.predict(X_train)\n",
        "\n",
        "# Print the R2, MAE, MSE, and RMSE for Train and Test data\n",
        "print('Train set')\n",
        "print('R2 score:', r2_score(y_train, y_train_pred))\n",
        "print('MAE:', mean_absolute_error(y_train, y_train_pred))\n",
        "print('MSE:', mean_squared_error(y_train, y_train_pred))\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
        "\n",
        "# Additional metrics\n",
        "print(\"\\nAdditional metrics for Train set:\")\n",
        "print('MAPE:', mean_absolute_percentage_error(y_train, y_train_pred))\n",
        "print('MBE:', np.mean(y_train_pred - y_train))\n",
        "print('EVS:', explained_variance_score(y_train, y_train_pred))\n",
        "print('MedAE:', median_absolute_error(y_train, y_train_pred))\n",
        "print('CV:', np.sqrt(mean_squared_error(y_train, y_train_pred)) / np.mean(y_train))\n",
        "\n",
        "print('\\nAdditional metrics for Test set:')\n",
        "print('MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
        "print('MBE:', np.mean(y_pred - y_test))\n",
        "print('EVS:', explained_variance_score(y_test, y_pred))\n",
        "print('MedAE:', median_absolute_error(y_test, y_pred))\n",
        "print('CV:', np.sqrt(mean_squared_error(y_test, y_pred)) / np.mean(y_test))\n"
      ],
      "metadata": {
        "id": "sBumLGf9Y3bH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}